---
title: "Tidy text"
author: "Alison E. Turnbull"
date: "2/23/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r packages, include=FALSE}
library(tidyverse)
library(here)
library(ggplot2)
library(knitr)
library(kableExtra)
library(forcats)
library(stringr)
library(tidytext)
library(textdata)
```

#### Load data
```{r load data}
data <- read_csv(here::here("data", "20200218_COPD Qualanalysis data.csv"), col_types = cols())
```

### Tokenization of comments
```{r tokenization}
  t_data<- data %>%
              mutate(gold_doc_comment= ifelse(!is.na(comment_cat), "Yes", "No")) %>%
              filter(gold_doc_comment=="Yes") %>%
              select(uid, comment) %>%
              unnest_tokens(word, comment)
```

### Remove stop words
```{r stopwords}
  t_data<-t_data %>% 
      anti_join(stop_words)
```

### How long were most people's comments?
```{r length of comment}
by_uid<-t_data %>%
         group_by(uid) %>%
            count(uid)

ggplot(by_uid, aes(x=n)) + geom_histogram(color="black", fill="gray", binwidth = 1) +
                labs(title = "How many words (excluding stop words) are in open-ended responses?", x="Number of words", y="Number of responses") +
                      theme_bw()
```




### Looking at the most common words in comments about doctors (excluding stop words)
```{r common words}

  t_data %>%
      count(word, sort = TRUE) %>%
        filter(n >5) %>%
          mutate(word = reorder(word, n )) %>%
            ggplot(aes(word, n)) +
              geom_col() + 
                xlab(NULL) + 
                labs(title = "Words appearing >5 times in open-ended responses", y ="How many times this word appears in responses") +
                  coord_flip() +
                    theme_bw()

```

### Afinn lexicon 
```{r AFINN}
afinn<-t_data %>%
  inner_join(get_sentiments("afinn")) %>%
    group_by(uid) %>%
        summarise(sentiment = sum(value)) %>%
            mutate(method = "AFINN")


ggplot(afinn, aes(x=sentiment)) + geom_histogram(color="black", fill="gray", binwidth = 1) +
                labs(title = "Histogram of Afinn sentiment total", x="Sentiment", y="Number of responses") +
                      theme_bw()
```

### Bing lexicon 
```{r Bing}
bing<-t_data %>%
  inner_join(get_sentiments("bing")) %>%
    mutate(method = "Bing") %>%
      count(method, uid, sentiment) %>%
        spread(sentiment, n, fill=0) %>%
          mutate(total_sentiments = positive+negative) %>%
            mutate(net_sentiment = positive - negative)

ggplot(bing, aes(x=net_sentiment)) + geom_histogram(color="black", fill="gray", binwidth = 1) +
                labs(title = "Histogram of Net Bing Sentiment", x=" Net Sentiment", y="Number of responses") +
                      theme_bw()

```

### nrc lexicon 
```{r Bing}
nrc<-t_data %>%
  inner_join(get_sentiments("nrc")) %>%
    mutate(method = "NRC") %>%
      filter(sentiment %in% c("positive", "negative")) %>%
        count(method, uid, sentiment) %>%
          spread(sentiment, n, fill=0) %>%
            mutate(total_sentiments = positive+negative) %>%
              mutate(net_sentiment = positive - negative)
          

ggplot(nrc, aes(x=net_sentiment)) + geom_histogram(color="black", fill="gray", binwidth = 1) +
                labs(title = "Histogram of Net NRC Sentiment", x=" Net Sentiment", y="Number of responses") +
                      theme_bw()

```

## Looking at correlations between sentiment measures from the 3 lexicons

